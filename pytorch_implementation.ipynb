{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of pytorch_implementation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVlNPXiPaIjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc025e83-da0b-4707-889f-0123dffb01b0"
      },
      "source": [
        "cd drive/MyDrive/Colab\\ Notebooks/GSOC\\ 2021/ML4Sci"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/GSOC 2021/ML4Sci\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe4teuTF23XG"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "import h5py\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import Normalizer, StandardScaler\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vWQCHv2Xyrd"
      },
      "source": [
        "\n",
        "filename='Electron.hdf5'\n",
        "data1 = h5py.File(filename, 'r')\n",
        "Y1=data1['y']\n",
        "X1=data1['X']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rapHJQ_QX271"
      },
      "source": [
        "filename='Photon.hdf5'\n",
        "data0 = h5py.File(filename, 'r')\n",
        "Y0=data0['y']\n",
        "X0=data0['X']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK8OR44RX7hk"
      },
      "source": [
        "X_final=np.concatenate((X0[:],X1[:]),axis=0)\n",
        "Y_final=np.concatenate((Y0[:],Y1[:]),axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACgrilXKYDEn",
        "outputId": "41b2dbd5-745c-47be-f9e7-ccb3bd71b8ea"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_valid, Y_train, Y_valid = train_test_split(X_final[:,:,:,0].reshape((X_final.shape[0],1,X_final.shape[1],X_final.shape[2])),Y_final,test_size = 0.2, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_valid.shape,Y_valid.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(398400, 1, 32, 32) (398400,)\n",
            "(99600, 1, 32, 32) (99600,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TYeBCc87K33"
      },
      "source": [
        "import torch\n",
        "from torch.utils import data\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "  'Characterizes a dataset for PyTorch'\n",
        "  def __init__(self, inputs, labels):\n",
        "        'Initialization'\n",
        "        self.labels = labels\n",
        "        self.inputs = inputs\n",
        "\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.inputs)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "\n",
        "        # Get data and get label\n",
        "        X = self.inputs[index]\n",
        "        y = self.labels[index]\n",
        "\n",
        "        return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mZDNMyj79nH"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset={'input':X_train,'output':Y_train},\n",
        "                                          batch_size=100,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset={'input':X_valid},\n",
        "                                          batch_size=100,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnSJ54Tn8Pvx"
      },
      "source": [
        "\n",
        "window_height=32\n",
        "window_width=32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gd92d8U8VR4",
        "outputId": "873a228c-0946-4a9e-859e-0e1796532441"
      },
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
        "        #self.relu1 = nn.Relu()\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        #self.relu2 = nn.Relu()\n",
        "        self.conv3 = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "       # self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv5 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv6 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(4, 4)\n",
        "        #self.fc1 = nn.Flatten()\n",
        "        #self.relu3 = nn.Relu()\n",
        "        #self.fc1 = nn.Linear(256, 128)\n",
        "        #self.relu4 = nn.Relu()\n",
        "        #self.fc3 = nn.Linear(1024, 256)\n",
        "        self.fc1 = nn.Linear(128, 64)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "        #self.fc2 = nn.Linear(128, 1)\n",
        "        #self.sigmoid1 = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        #x = F.relu(self.conv2(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        #x = F.relu(self.conv4(x))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = F.relu(self.conv5(x))\n",
        "       # x = F.relu(self.conv6(x))\n",
        "        x = self.pool1(F.relu(self.conv6(x)))\n",
        "        #x = self.fc1()\n",
        "        x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
        "        x = F.leaky_relu(self.fc1(x))\n",
        "        #x = F.leaky_relu(self.fc2(x))\n",
        "       # x = F.leaky_relu(self.fc3(x))\n",
        "        x = F.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net.cuda()\n",
        "summary(net, (1, 32, 32), device='cuda')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 32, 32]              80\n",
            "            Conv2d-2            [-1, 8, 32, 32]             584\n",
            "         MaxPool2d-3            [-1, 8, 16, 16]               0\n",
            "            Conv2d-4           [-1, 32, 16, 16]           2,336\n",
            "            Conv2d-5           [-1, 32, 16, 16]           9,248\n",
            "         MaxPool2d-6             [-1, 32, 8, 8]               0\n",
            "            Conv2d-7             [-1, 32, 8, 8]           9,248\n",
            "            Conv2d-8             [-1, 32, 8, 8]           9,248\n",
            "         MaxPool2d-9             [-1, 32, 2, 2]               0\n",
            "           Linear-10                   [-1, 64]           8,256\n",
            "           Linear-11                    [-1, 1]              65\n",
            "================================================================\n",
            "Total params: 39,065\n",
            "Trainable params: 39,065\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.31\n",
            "Params size (MB): 0.15\n",
            "Estimated Total Size (MB): 0.47\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4n_R7dl8kzl"
      },
      "source": [
        "# ## Define CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, activation='relu', kernel_size=3, padding='same', kernel_initializer='GlorotNormal', input_shape=(img_rows, img_cols, nb_channels)))\n",
        "model.add(Conv2D(8, activation='relu', kernel_size=3, padding='same', kernel_initializer='GlorotNormal'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, activation='relu', kernel_size=3, padding='same', kernel_initializer='GlorotNormal'))\n",
        "model.add(Conv2D(32, activation='relu', kernel_size=3, padding='same', kernel_initializer='GlorotNormal'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, activation='relu', kernel_size=5, padding='same', kernel_initializer='GlorotNormal'))\n",
        "model.add(Conv2D(32, activation='relu', kernel_size=5, padding='same', kernel_initializer='GlorotNormal'))\n",
        "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu', kernel_initializer='GlorotNormal'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='GlorotNormal'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid', kernel_initializer='GlorotNormal'))\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr_init), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxQCqBRk-YZU"
      },
      "source": [
        "use_cuda = True\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    net.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXE-kVjL-d6G"
      },
      "source": [
        "batch_size=1024\n",
        "import torch\n",
        "from torch.utils import data\n",
        "#import cudnn\n",
        "#from my_classes import Dataset\n",
        "\n",
        "\n",
        "# CUDA for PyTorch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "#cudnn.benchmark = True\n",
        "\n",
        "# Parameters\n",
        "params = {'batch_size': batch_size,\n",
        "          'shuffle': True,\n",
        "          }\n",
        "max_epochs = 100\n",
        "\n",
        "# Generators\n",
        "training_set = Dataset(X_train, Y_train)\n",
        "training_generator = data.DataLoader(training_set, **params)\n",
        "\n",
        "validation_set = Dataset(X_valid, Y_valid)\n",
        "validation_generator = data.DataLoader(validation_set, **params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNOWIUF--hIc"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuPefi1p-kZ_",
        "outputId": "f672e2a4-fb01-4512-a1c6-568aa6192bb0"
      },
      "source": [
        "num_epochs=40\n",
        "correct=0\n",
        "total=0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(training_generator):   # Load a batch of images with its (index, data, class)\n",
        "        #images = Variable(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
        "        #labels = Variable(labels)\n",
        "        \n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
        "        outputs = net(inputs)\n",
        "                                      # Forward pass: compute the output class given a image\n",
        "        loss = criterion(outputs[:,0], labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
        "        loss.backward()                                   # Backward pass: compute the weight\n",
        "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
        "        outputs[outputs>0.5]=1\n",
        "        outputs[outputs<0.5]=0\n",
        "        total += labels.shape[0]\n",
        "                                        # Increment the total count\n",
        "        correct += (outputs[:,0] == labels).sum()\n",
        "        \n",
        "        if (i+1) % 100 == 0:                              # Logging\n",
        "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Accuracy: %.4f'\n",
        "                 %(epoch+1, num_epochs, i+1, len(X_train)//batch_size, loss.item(), ((100 * correct.item() / total))))\n",
        "    #outputs = net(X_valid0.cuda())                             # Forward pass: compute the output class given a image\n",
        "    #loss = criterion(outputs, Y_valid.cuda())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/40], Step [100/389], Loss: 0.6781, Accuracy: 51.5498\n",
            "Epoch [1/40], Step [200/389], Loss: 0.6609, Accuracy: 55.1655\n",
            "Epoch [1/40], Step [300/389], Loss: 0.6469, Accuracy: 56.7878\n",
            "Epoch [2/40], Step [100/389], Loss: 0.6155, Accuracy: 59.4880\n",
            "Epoch [2/40], Step [200/389], Loss: 0.5968, Accuracy: 60.9577\n",
            "Epoch [2/40], Step [300/389], Loss: 0.5986, Accuracy: 62.1689\n",
            "Epoch [3/40], Step [100/389], Loss: 0.5732, Accuracy: 63.7423\n",
            "Epoch [3/40], Step [200/389], Loss: 0.5738, Accuracy: 64.4247\n",
            "Epoch [3/40], Step [300/389], Loss: 0.5844, Accuracy: 64.9768\n",
            "Epoch [4/40], Step [100/389], Loss: 0.5752, Accuracy: 65.7982\n",
            "Epoch [4/40], Step [200/389], Loss: 0.5832, Accuracy: 66.1797\n",
            "Epoch [4/40], Step [300/389], Loss: 0.5966, Accuracy: 66.4859\n",
            "Epoch [5/40], Step [100/389], Loss: 0.5778, Accuracy: 66.9699\n",
            "Epoch [5/40], Step [200/389], Loss: 0.5633, Accuracy: 67.1867\n",
            "Epoch [5/40], Step [300/389], Loss: 0.5737, Accuracy: 67.4059\n",
            "Epoch [6/40], Step [100/389], Loss: 0.5589, Accuracy: 67.7669\n",
            "Epoch [6/40], Step [200/389], Loss: 0.5745, Accuracy: 67.9259\n",
            "Epoch [6/40], Step [300/389], Loss: 0.5593, Accuracy: 68.0785\n",
            "Epoch [7/40], Step [100/389], Loss: 0.5710, Accuracy: 68.3464\n",
            "Epoch [7/40], Step [200/389], Loss: 0.5439, Accuracy: 68.4675\n",
            "Epoch [7/40], Step [300/389], Loss: 0.5502, Accuracy: 68.5751\n",
            "Epoch [8/40], Step [100/389], Loss: 0.5861, Accuracy: 68.7901\n",
            "Epoch [8/40], Step [200/389], Loss: 0.5470, Accuracy: 68.8868\n",
            "Epoch [8/40], Step [300/389], Loss: 0.5540, Accuracy: 68.9929\n",
            "Epoch [9/40], Step [100/389], Loss: 0.5572, Accuracy: 69.1566\n",
            "Epoch [9/40], Step [200/389], Loss: 0.5446, Accuracy: 69.2333\n",
            "Epoch [9/40], Step [300/389], Loss: 0.5691, Accuracy: 69.3058\n",
            "Epoch [10/40], Step [100/389], Loss: 0.5689, Accuracy: 69.4464\n",
            "Epoch [10/40], Step [200/389], Loss: 0.5582, Accuracy: 69.5111\n",
            "Epoch [10/40], Step [300/389], Loss: 0.5361, Accuracy: 69.5824\n",
            "Epoch [11/40], Step [100/389], Loss: 0.5882, Accuracy: 69.6974\n",
            "Epoch [11/40], Step [200/389], Loss: 0.5489, Accuracy: 69.7552\n",
            "Epoch [11/40], Step [300/389], Loss: 0.5512, Accuracy: 69.8211\n",
            "Epoch [12/40], Step [100/389], Loss: 0.5513, Accuracy: 69.9333\n",
            "Epoch [12/40], Step [200/389], Loss: 0.5957, Accuracy: 69.9898\n",
            "Epoch [12/40], Step [300/389], Loss: 0.5675, Accuracy: 70.0377\n",
            "Epoch [13/40], Step [100/389], Loss: 0.5299, Accuracy: 70.1270\n",
            "Epoch [13/40], Step [200/389], Loss: 0.5491, Accuracy: 70.1758\n",
            "Epoch [13/40], Step [300/389], Loss: 0.5553, Accuracy: 70.2191\n",
            "Epoch [14/40], Step [100/389], Loss: 0.5663, Accuracy: 70.3036\n",
            "Epoch [14/40], Step [200/389], Loss: 0.5603, Accuracy: 70.3426\n",
            "Epoch [14/40], Step [300/389], Loss: 0.5570, Accuracy: 70.3756\n",
            "Epoch [15/40], Step [100/389], Loss: 0.5675, Accuracy: 70.4482\n",
            "Epoch [15/40], Step [200/389], Loss: 0.5392, Accuracy: 70.4842\n",
            "Epoch [15/40], Step [300/389], Loss: 0.5660, Accuracy: 70.5200\n",
            "Epoch [16/40], Step [100/389], Loss: 0.5237, Accuracy: 70.5887\n",
            "Epoch [16/40], Step [200/389], Loss: 0.5667, Accuracy: 70.6239\n",
            "Epoch [16/40], Step [300/389], Loss: 0.5411, Accuracy: 70.6574\n",
            "Epoch [17/40], Step [100/389], Loss: 0.5523, Accuracy: 70.7144\n",
            "Epoch [17/40], Step [200/389], Loss: 0.5791, Accuracy: 70.7415\n",
            "Epoch [17/40], Step [300/389], Loss: 0.5568, Accuracy: 70.7722\n",
            "Epoch [18/40], Step [100/389], Loss: 0.5607, Accuracy: 70.8262\n",
            "Epoch [18/40], Step [200/389], Loss: 0.5630, Accuracy: 70.8503\n",
            "Epoch [18/40], Step [300/389], Loss: 0.5692, Accuracy: 70.8763\n",
            "Epoch [19/40], Step [100/389], Loss: 0.5346, Accuracy: 70.9258\n",
            "Epoch [19/40], Step [200/389], Loss: 0.5429, Accuracy: 70.9519\n",
            "Epoch [19/40], Step [300/389], Loss: 0.5617, Accuracy: 70.9772\n",
            "Epoch [20/40], Step [100/389], Loss: 0.5525, Accuracy: 71.0222\n",
            "Epoch [20/40], Step [200/389], Loss: 0.5717, Accuracy: 71.0431\n",
            "Epoch [20/40], Step [300/389], Loss: 0.5364, Accuracy: 71.0682\n",
            "Epoch [21/40], Step [100/389], Loss: 0.5624, Accuracy: 71.1094\n",
            "Epoch [21/40], Step [200/389], Loss: 0.5826, Accuracy: 71.1295\n",
            "Epoch [21/40], Step [300/389], Loss: 0.5564, Accuracy: 71.1510\n",
            "Epoch [22/40], Step [100/389], Loss: 0.5301, Accuracy: 71.1896\n",
            "Epoch [22/40], Step [200/389], Loss: 0.5209, Accuracy: 71.2102\n",
            "Epoch [22/40], Step [300/389], Loss: 0.5361, Accuracy: 71.2303\n",
            "Epoch [23/40], Step [100/389], Loss: 0.5687, Accuracy: 71.2670\n",
            "Epoch [23/40], Step [200/389], Loss: 0.5207, Accuracy: 71.2866\n",
            "Epoch [23/40], Step [300/389], Loss: 0.5471, Accuracy: 71.3031\n",
            "Epoch [24/40], Step [100/389], Loss: 0.5310, Accuracy: 71.3368\n",
            "Epoch [24/40], Step [200/389], Loss: 0.5276, Accuracy: 71.3545\n",
            "Epoch [24/40], Step [300/389], Loss: 0.5563, Accuracy: 71.3710\n",
            "Epoch [25/40], Step [100/389], Loss: 0.5576, Accuracy: 71.4056\n",
            "Epoch [25/40], Step [200/389], Loss: 0.5638, Accuracy: 71.4218\n",
            "Epoch [25/40], Step [300/389], Loss: 0.5426, Accuracy: 71.4396\n",
            "Epoch [26/40], Step [100/389], Loss: 0.5447, Accuracy: 71.4691\n",
            "Epoch [26/40], Step [200/389], Loss: 0.5442, Accuracy: 71.4849\n",
            "Epoch [26/40], Step [300/389], Loss: 0.5330, Accuracy: 71.4997\n",
            "Epoch [27/40], Step [100/389], Loss: 0.5333, Accuracy: 71.5274\n",
            "Epoch [27/40], Step [200/389], Loss: 0.5341, Accuracy: 71.5429\n",
            "Epoch [27/40], Step [300/389], Loss: 0.5553, Accuracy: 71.5573\n",
            "Epoch [28/40], Step [100/389], Loss: 0.5263, Accuracy: 71.5821\n",
            "Epoch [28/40], Step [200/389], Loss: 0.5428, Accuracy: 71.5980\n",
            "Epoch [28/40], Step [300/389], Loss: 0.5188, Accuracy: 71.6112\n",
            "Epoch [29/40], Step [100/389], Loss: 0.5614, Accuracy: 71.6368\n",
            "Epoch [29/40], Step [200/389], Loss: 0.5518, Accuracy: 71.6499\n",
            "Epoch [29/40], Step [300/389], Loss: 0.5504, Accuracy: 71.6635\n",
            "Epoch [30/40], Step [100/389], Loss: 0.5494, Accuracy: 71.6859\n",
            "Epoch [30/40], Step [200/389], Loss: 0.5267, Accuracy: 71.6980\n",
            "Epoch [30/40], Step [300/389], Loss: 0.5219, Accuracy: 71.7121\n",
            "Epoch [31/40], Step [100/389], Loss: 0.5419, Accuracy: 71.7350\n",
            "Epoch [31/40], Step [200/389], Loss: 0.5249, Accuracy: 71.7465\n",
            "Epoch [31/40], Step [300/389], Loss: 0.5532, Accuracy: 71.7577\n",
            "Epoch [32/40], Step [100/389], Loss: 0.5734, Accuracy: 71.7805\n",
            "Epoch [32/40], Step [200/389], Loss: 0.5352, Accuracy: 71.7939\n",
            "Epoch [32/40], Step [300/389], Loss: 0.5714, Accuracy: 71.8061\n",
            "Epoch [33/40], Step [100/389], Loss: 0.5402, Accuracy: 71.8257\n",
            "Epoch [33/40], Step [200/389], Loss: 0.5312, Accuracy: 71.8376\n",
            "Epoch [33/40], Step [300/389], Loss: 0.5338, Accuracy: 71.8478\n",
            "Epoch [34/40], Step [100/389], Loss: 0.5345, Accuracy: 71.8680\n",
            "Epoch [34/40], Step [200/389], Loss: 0.5461, Accuracy: 71.8805\n",
            "Epoch [34/40], Step [300/389], Loss: 0.5335, Accuracy: 71.8909\n",
            "Epoch [35/40], Step [100/389], Loss: 0.5499, Accuracy: 71.9097\n",
            "Epoch [35/40], Step [200/389], Loss: 0.5266, Accuracy: 71.9200\n",
            "Epoch [35/40], Step [300/389], Loss: 0.5099, Accuracy: 71.9328\n",
            "Epoch [36/40], Step [100/389], Loss: 0.5477, Accuracy: 71.9511\n",
            "Epoch [36/40], Step [200/389], Loss: 0.5311, Accuracy: 71.9607\n",
            "Epoch [36/40], Step [300/389], Loss: 0.5317, Accuracy: 71.9709\n",
            "Epoch [37/40], Step [100/389], Loss: 0.5427, Accuracy: 71.9865\n",
            "Epoch [37/40], Step [200/389], Loss: 0.5014, Accuracy: 71.9965\n",
            "Epoch [37/40], Step [300/389], Loss: 0.5576, Accuracy: 72.0061\n",
            "Epoch [38/40], Step [100/389], Loss: 0.5616, Accuracy: 72.0249\n",
            "Epoch [38/40], Step [200/389], Loss: 0.5626, Accuracy: 72.0340\n",
            "Epoch [38/40], Step [300/389], Loss: 0.5457, Accuracy: 72.0420\n",
            "Epoch [39/40], Step [100/389], Loss: 0.5228, Accuracy: 72.0607\n",
            "Epoch [39/40], Step [200/389], Loss: 0.5330, Accuracy: 72.0688\n",
            "Epoch [39/40], Step [300/389], Loss: 0.5431, Accuracy: 72.0788\n",
            "Epoch [40/40], Step [100/389], Loss: 0.5332, Accuracy: 72.0940\n",
            "Epoch [40/40], Step [200/389], Loss: 0.5356, Accuracy: 72.1031\n",
            "Epoch [40/40], Step [300/389], Loss: 0.5241, Accuracy: 72.1116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RBZ03KTcF3g"
      },
      "source": [
        "torch.save(net.state_dict(), 'pytorch2.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg3ia4Ukb6l4",
        "outputId": "6e78e611-557b-44ef-8a58-d875c90d7225"
      },
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load('pytorch2.pt'))\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    net.cuda()\n",
        "net.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv5): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool1): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAvSZi-qcQg_",
        "outputId": "41f17d87-a04e-48c7-81f3-efdb9554a1ca"
      },
      "source": [
        "pred=torch.Tensor.cpu(net(inputs[0:10000])).detach().numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5OIldY7cTcP"
      },
      "source": [
        "\n",
        "true_vals=torch.Tensor.cpu(labels[:10000]).detach().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBmZptt7b7AI"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "y_pred = pred.ravel()\n",
        "fpr, tpr, thresholds = roc_curve(true_vals, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q73pEZicL-l"
      },
      "source": [
        "\n",
        "from sklearn.metrics import auc\n",
        "auc_keras = auc(fpr, tpr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmKv8vSYfpRl"
      },
      "source": [
        "score = nn.eval(X_valid, y_valid, verbose=1)\n",
        "print('\\nValidation loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n",
        "y_pred = nn.predict(X_valid)\n",
        "fpr, tpr, _ = roc_curve(y_valid, y_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print('Validation ROC AUC:', roc_auc)\n",
        "\n",
        "# Evaluate on test set\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('\\nTest loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n",
        "y_pred = model.predict(X_test)\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print('Test ROC AUC:', roc_auc)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}